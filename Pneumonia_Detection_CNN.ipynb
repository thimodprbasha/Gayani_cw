{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Chest X-Ray Pneumonia Detection using Convolutional Neural Networks\n",
                "\n",
                "## 6COSC020W Coursework - Part C Implementation\n",
                "\n",
                "This notebook implements a CNN-based binary classifier for detecting pneumonia from chest X-ray images. The model is trained on the Kaggle Chest X-Ray Images (Pneumonia) dataset containing 5,863 images from pediatric patients.\n",
                "\n",
                "**Author:** Student Name  \n",
                "**Date:** January 2026  \n",
                "**Domain:** Healthcare Diagnostics - Medical Imaging"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 1. Environment Setup and Library Imports\n",
                "\n",
                "Import all necessary libraries for data processing, model building, training, and evaluation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Core libraries\n",
                "import os\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Visualization\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "\n",
                "# Image processing\n",
                "from PIL import Image\n",
                "\n",
                "# TensorFlow and Keras\n",
                "import tensorflow as tf\n",
                "from tensorflow import keras\n",
                "from tensorflow.keras import layers, models, optimizers\n",
                "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
                "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
                "\n",
                "# Evaluation metrics\n",
                "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
                "from sklearn.metrics import precision_score, recall_score, f1_score, roc_curve, auc\n",
                "\n",
                "# Set random seeds for reproducibility\n",
                "np.random.seed(42)\n",
                "tf.random.set_seed(42)\n",
                "\n",
                "print(f\"TensorFlow Version: {tf.__version__}\")\n",
                "print(f\"Keras Version: {keras.__version__}\")\n",
                "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 2. Dataset Configuration\n",
                "\n",
                "Define paths to the dataset directories and configure image parameters. The dataset should be downloaded from Kaggle and extracted to the specified location.\n",
                "\n",
                "**Dataset Source:** [Chest X-Ray Images (Pneumonia) - Kaggle](https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Configuration constants\n",
                "IMAGE_SIZE = (150, 150)  # Target image dimensions\n",
                "BATCH_SIZE = 32          # Training batch size\n",
                "EPOCHS = 15              # Maximum training epochs\n",
                "LEARNING_RATE = 0.0001   # Initial learning rate\n",
                "\n",
                "# Dataset paths - UPDATE THESE PATHS TO YOUR LOCAL DATASET LOCATION\n",
                "# Download from: https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia\n",
                "BASE_DIR = './chest_xray'  # Root directory of the dataset\n",
                "TRAIN_DIR = os.path.join(BASE_DIR, 'train')\n",
                "VAL_DIR = os.path.join(BASE_DIR, 'val')\n",
                "TEST_DIR = os.path.join(BASE_DIR, 'test')\n",
                "\n",
                "# Class labels\n",
                "CLASSES = ['NORMAL', 'PNEUMONIA']\n",
                "\n",
                "print(f\"Configuration:\")\n",
                "print(f\"  Image Size: {IMAGE_SIZE}\")\n",
                "print(f\"  Batch Size: {BATCH_SIZE}\")\n",
                "print(f\"  Max Epochs: {EPOCHS}\")\n",
                "print(f\"  Learning Rate: {LEARNING_RATE}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 3. Data Exploration and Analysis\n",
                "\n",
                "Explore the dataset structure, examine class distribution, and visualize sample images to understand the data characteristics."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def count_images_in_directory(directory):\n",
                "    \"\"\"\n",
                "    Count the number of images in each class subdirectory.\n",
                "    \n",
                "    Args:\n",
                "        directory: Path to the parent directory containing class folders\n",
                "    \n",
                "    Returns:\n",
                "        Dictionary with class names as keys and image counts as values\n",
                "    \"\"\"\n",
                "    counts = {}\n",
                "    for class_name in CLASSES:\n",
                "        class_path = os.path.join(directory, class_name)\n",
                "        if os.path.exists(class_path):\n",
                "            counts[class_name] = len([f for f in os.listdir(class_path) \n",
                "                                      if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
                "        else:\n",
                "            counts[class_name] = 0\n",
                "    return counts\n",
                "\n",
                "# Count images in each split\n",
                "print(\"Dataset Distribution:\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "for split_name, split_dir in [('Training', TRAIN_DIR), ('Validation', VAL_DIR), ('Test', TEST_DIR)]:\n",
                "    counts = count_images_in_directory(split_dir)\n",
                "    total = sum(counts.values())\n",
                "    print(f\"\\n{split_name}:\")\n",
                "    for class_name, count in counts.items():\n",
                "        percentage = (count / total * 100) if total > 0 else 0\n",
                "        print(f\"  {class_name}: {count:,} images ({percentage:.1f}%)\")\n",
                "    print(f\"  Total: {total:,} images\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def visualize_sample_images(directory, n_samples=4):\n",
                "    \"\"\"\n",
                "    Display sample images from each class for visual inspection.\n",
                "    \n",
                "    Args:\n",
                "        directory: Path to the parent directory containing class folders\n",
                "        n_samples: Number of samples to display per class\n",
                "    \"\"\"\n",
                "    fig, axes = plt.subplots(2, n_samples, figsize=(16, 8))\n",
                "    fig.suptitle('Sample Chest X-Ray Images', fontsize=16, fontweight='bold')\n",
                "    \n",
                "    for row_idx, class_name in enumerate(CLASSES):\n",
                "        class_path = os.path.join(directory, class_name)\n",
                "        if not os.path.exists(class_path):\n",
                "            continue\n",
                "            \n",
                "        image_files = [f for f in os.listdir(class_path) \n",
                "                       if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
                "        sample_files = np.random.choice(image_files, min(n_samples, len(image_files)), replace=False)\n",
                "        \n",
                "        for col_idx, img_file in enumerate(sample_files):\n",
                "            img_path = os.path.join(class_path, img_file)\n",
                "            img = Image.open(img_path)\n",
                "            \n",
                "            ax = axes[row_idx, col_idx]\n",
                "            ax.imshow(img, cmap='gray')\n",
                "            ax.set_title(f'{class_name}', fontsize=12, fontweight='bold',\n",
                "                        color='green' if class_name == 'NORMAL' else 'red')\n",
                "            ax.axis('off')\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "# Visualize sample training images\n",
                "visualize_sample_images(TRAIN_DIR, n_samples=4)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize class distribution as bar chart\n",
                "train_counts = count_images_in_directory(TRAIN_DIR)\n",
                "test_counts = count_images_in_directory(TEST_DIR)\n",
                "\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# Training set distribution\n",
                "colors = ['#2ecc71', '#e74c3c']\n",
                "axes[0].bar(train_counts.keys(), train_counts.values(), color=colors, edgecolor='black', linewidth=1.5)\n",
                "axes[0].set_title('Training Set Distribution', fontsize=14, fontweight='bold')\n",
                "axes[0].set_xlabel('Class', fontsize=12)\n",
                "axes[0].set_ylabel('Number of Images', fontsize=12)\n",
                "for i, (k, v) in enumerate(train_counts.items()):\n",
                "    axes[0].text(i, v + 50, str(v), ha='center', fontsize=12, fontweight='bold')\n",
                "\n",
                "# Test set distribution\n",
                "axes[1].bar(test_counts.keys(), test_counts.values(), color=colors, edgecolor='black', linewidth=1.5)\n",
                "axes[1].set_title('Test Set Distribution', fontsize=14, fontweight='bold')\n",
                "axes[1].set_xlabel('Class', fontsize=12)\n",
                "axes[1].set_ylabel('Number of Images', fontsize=12)\n",
                "for i, (k, v) in enumerate(test_counts.items()):\n",
                "    axes[1].text(i, v + 10, str(v), ha='center', fontsize=12, fontweight='bold')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# Note on class imbalance\n",
                "imbalance_ratio = train_counts['PNEUMONIA'] / train_counts['NORMAL']\n",
                "print(f\"\\nClass Imbalance Ratio (PNEUMONIA:NORMAL): {imbalance_ratio:.2f}:1\")\n",
                "print(\"Note: The dataset is imbalanced with more PNEUMONIA cases. Consider class weights during training.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 4. Data Pre-processing and Augmentation\n",
                "\n",
                "Configure data generators for loading, preprocessing, and augmenting images during training. Data augmentation helps improve model generalization by artificially expanding the training set."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Data augmentation for training set\n",
                "# Augmentation helps reduce overfitting and improves generalization\n",
                "train_datagen = ImageDataGenerator(\n",
                "    rescale=1./255,           # Normalize pixel values to [0, 1]\n",
                "    rotation_range=20,         # Random rotation up to 20 degrees\n",
                "    width_shift_range=0.1,     # Horizontal shift up to 10%\n",
                "    height_shift_range=0.1,    # Vertical shift up to 10%\n",
                "    shear_range=0.1,           # Shear transformation\n",
                "    zoom_range=0.1,            # Random zoom up to 10%\n",
                "    horizontal_flip=True,      # Random horizontal flip\n",
                "    fill_mode='nearest',       # Fill strategy for new pixels\n",
                "    validation_split=0.2       # Use 20% of training data for validation\n",
                ")\n",
                "\n",
                "# No augmentation for validation and test sets - only normalization\n",
                "test_datagen = ImageDataGenerator(rescale=1./255)\n",
                "\n",
                "print(\"Data generators configured with the following augmentations:\")\n",
                "print(\"  - Rotation: ±20 degrees\")\n",
                "print(\"  - Width/Height Shift: ±10%\")\n",
                "print(\"  - Shear: 10%\")\n",
                "print(\"  - Zoom: ±10%\")\n",
                "print(\"  - Horizontal Flip: Enabled\")\n",
                "print(\"  - Validation Split: 20% from training data\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create data generators for training, validation, and testing\n",
                "# Using flow_from_directory to load images directly from folders\n",
                "\n",
                "# Training generator (with augmentation)\n",
                "train_generator = train_datagen.flow_from_directory(\n",
                "    TRAIN_DIR,\n",
                "    target_size=IMAGE_SIZE,\n",
                "    batch_size=BATCH_SIZE,\n",
                "    class_mode='binary',       # Binary classification\n",
                "    subset='training',         # Use training subset\n",
                "    shuffle=True,\n",
                "    seed=42\n",
                ")\n",
                "\n",
                "# Validation generator (from training data, no augmentation behavior applied)\n",
                "validation_generator = train_datagen.flow_from_directory(\n",
                "    TRAIN_DIR,\n",
                "    target_size=IMAGE_SIZE,\n",
                "    batch_size=BATCH_SIZE,\n",
                "    class_mode='binary',\n",
                "    subset='validation',       # Use validation subset\n",
                "    shuffle=False,\n",
                "    seed=42\n",
                ")\n",
                "\n",
                "# Test generator (no augmentation)\n",
                "test_generator = test_datagen.flow_from_directory(\n",
                "    TEST_DIR,\n",
                "    target_size=IMAGE_SIZE,\n",
                "    batch_size=BATCH_SIZE,\n",
                "    class_mode='binary',\n",
                "    shuffle=False              # Keep order for evaluation\n",
                ")\n",
                "\n",
                "# Print class indices mapping\n",
                "print(f\"\\nClass Indices: {train_generator.class_indices}\")\n",
                "print(f\"Training Samples: {train_generator.samples}\")\n",
                "print(f\"Validation Samples: {validation_generator.samples}\")\n",
                "print(f\"Test Samples: {test_generator.samples}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize augmented images to verify augmentation is working\n",
                "def visualize_augmentation(generator, n_samples=6):\n",
                "    \"\"\"\n",
                "    Display augmented versions of images from the generator.\n",
                "    \n",
                "    Args:\n",
                "        generator: Image data generator\n",
                "        n_samples: Number of augmented samples to display\n",
                "    \"\"\"\n",
                "    fig, axes = plt.subplots(2, n_samples, figsize=(18, 6))\n",
                "    fig.suptitle('Data Augmentation Examples', fontsize=16, fontweight='bold')\n",
                "    \n",
                "    # Get a batch of augmented images\n",
                "    batch_x, batch_y = next(generator)\n",
                "    \n",
                "    for i in range(min(n_samples * 2, len(batch_x))):\n",
                "        row = i // n_samples\n",
                "        col = i % n_samples\n",
                "        ax = axes[row, col]\n",
                "        ax.imshow(batch_x[i])\n",
                "        label = 'PNEUMONIA' if batch_y[i] == 1 else 'NORMAL'\n",
                "        ax.set_title(label, fontsize=10, color='red' if batch_y[i] == 1 else 'green')\n",
                "        ax.axis('off')\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "# Visualize augmented training images\n",
                "visualize_augmentation(train_generator, n_samples=6)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 5. CNN Model Architecture\n",
                "\n",
                "Define the Convolutional Neural Network architecture for pneumonia detection. The model uses three convolutional blocks with batch normalization, followed by dense layers for classification."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def build_cnn_model(input_shape=(150, 150, 3)):\n",
                "    \"\"\"\n",
                "    Build a CNN model for binary image classification.\n",
                "    \n",
                "    Architecture:\n",
                "    - 3 Convolutional blocks (Conv2D + BatchNorm + MaxPool)\n",
                "    - Flatten layer\n",
                "    - Dense layer with dropout for regularization\n",
                "    - Output layer with sigmoid activation\n",
                "    \n",
                "    Args:\n",
                "        input_shape: Shape of input images (height, width, channels)\n",
                "    \n",
                "    Returns:\n",
                "        Compiled Keras model\n",
                "    \"\"\"\n",
                "    model = models.Sequential(name='pneumonia_cnn')\n",
                "    \n",
                "    # Input layer\n",
                "    model.add(layers.Input(shape=input_shape))\n",
                "    \n",
                "    # Convolutional Block 1\n",
                "    model.add(layers.Conv2D(32, (3, 3), activation='relu', name='conv2d_1'))\n",
                "    model.add(layers.BatchNormalization(name='batch_norm_1'))\n",
                "    model.add(layers.MaxPooling2D((2, 2), name='max_pool_1'))\n",
                "    \n",
                "    # Convolutional Block 2\n",
                "    model.add(layers.Conv2D(64, (3, 3), activation='relu', name='conv2d_2'))\n",
                "    model.add(layers.BatchNormalization(name='batch_norm_2'))\n",
                "    model.add(layers.MaxPooling2D((2, 2), name='max_pool_2'))\n",
                "    \n",
                "    # Convolutional Block 3\n",
                "    model.add(layers.Conv2D(128, (3, 3), activation='relu', name='conv2d_3'))\n",
                "    model.add(layers.BatchNormalization(name='batch_norm_3'))\n",
                "    model.add(layers.MaxPooling2D((2, 2), name='max_pool_3'))\n",
                "    \n",
                "    # Flatten and Dense Layers\n",
                "    model.add(layers.Flatten(name='flatten'))\n",
                "    model.add(layers.Dense(256, activation='relu', name='dense_1'))\n",
                "    model.add(layers.Dropout(0.5, name='dropout'))  # Regularization\n",
                "    \n",
                "    # Output Layer\n",
                "    model.add(layers.Dense(1, activation='sigmoid', name='output'))\n",
                "    \n",
                "    return model\n",
                "\n",
                "# Build the model\n",
                "model = build_cnn_model(input_shape=(*IMAGE_SIZE, 3))\n",
                "\n",
                "# Display model summary\n",
                "print(\"Model Architecture:\")\n",
                "print(\"=\" * 70)\n",
                "model.summary()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compile the model\n",
                "model.compile(\n",
                "    optimizer=optimizers.Adam(learning_rate=LEARNING_RATE),\n",
                "    loss='binary_crossentropy',\n",
                "    metrics=['accuracy']\n",
                ")\n",
                "\n",
                "print(\"Model compiled with:\")\n",
                "print(f\"  Optimizer: Adam (lr={LEARNING_RATE})\")\n",
                "print(f\"  Loss: Binary Cross-Entropy\")\n",
                "print(f\"  Metrics: Accuracy\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize model architecture\n",
                "try:\n",
                "    from tensorflow.keras.utils import plot_model\n",
                "    plot_model(model, to_file='model_architecture.png', show_shapes=True, \n",
                "               show_layer_names=True, dpi=100)\n",
                "    print(\"Model architecture diagram saved to 'model_architecture.png'\")\n",
                "except Exception as e:\n",
                "    print(f\"Could not generate model diagram: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 6. Model Training\n",
                "\n",
                "Train the CNN model with callbacks for early stopping and learning rate reduction. Class weights are applied to handle the imbalanced dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate class weights to handle imbalanced data\n",
                "train_counts = count_images_in_directory(TRAIN_DIR)\n",
                "total_samples = sum(train_counts.values())\n",
                "n_classes = len(CLASSES)\n",
                "\n",
                "class_weights = {\n",
                "    0: total_samples / (n_classes * train_counts['NORMAL']),   # Weight for NORMAL\n",
                "    1: total_samples / (n_classes * train_counts['PNEUMONIA']) # Weight for PNEUMONIA\n",
                "}\n",
                "\n",
                "print(\"Class Weights for Imbalanced Data:\")\n",
                "print(f\"  NORMAL (0): {class_weights[0]:.4f}\")\n",
                "print(f\"  PNEUMONIA (1): {class_weights[1]:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define callbacks\n",
                "callbacks = [\n",
                "    # Early stopping to prevent overfitting\n",
                "    EarlyStopping(\n",
                "        monitor='val_loss',\n",
                "        patience=5,\n",
                "        restore_best_weights=True,\n",
                "        verbose=1\n",
                "    ),\n",
                "    # Reduce learning rate when validation loss plateaus\n",
                "    ReduceLROnPlateau(\n",
                "        monitor='val_loss',\n",
                "        factor=0.5,\n",
                "        patience=3,\n",
                "        min_lr=1e-7,\n",
                "        verbose=1\n",
                "    ),\n",
                "    # Save the best model\n",
                "    ModelCheckpoint(\n",
                "        'best_pneumonia_model.keras',\n",
                "        monitor='val_accuracy',\n",
                "        save_best_only=True,\n",
                "        verbose=1\n",
                "    )\n",
                "]\n",
                "\n",
                "print(\"Training callbacks configured:\")\n",
                "print(\"  - EarlyStopping (patience=5)\")\n",
                "print(\"  - ReduceLROnPlateau (factor=0.5, patience=3)\")\n",
                "print(\"  - ModelCheckpoint (save best model)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train the model\n",
                "print(\"\\nStarting model training...\")\n",
                "print(\"=\" * 70)\n",
                "\n",
                "history = model.fit(\n",
                "    train_generator,\n",
                "    epochs=EPOCHS,\n",
                "    validation_data=validation_generator,\n",
                "    class_weight=class_weights,\n",
                "    callbacks=callbacks,\n",
                "    verbose=1\n",
                ")\n",
                "\n",
                "print(\"\\nTraining completed!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 7. Training Visualization\n",
                "\n",
                "Plot training and validation accuracy/loss curves to analyze model performance during training."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_training_history(history):\n",
                "    \"\"\"\n",
                "    Plot training and validation accuracy/loss curves.\n",
                "    \n",
                "    Args:\n",
                "        history: Keras training history object\n",
                "    \"\"\"\n",
                "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
                "    \n",
                "    # Accuracy plot\n",
                "    axes[0].plot(history.history['accuracy'], label='Training Accuracy', \n",
                "                 linewidth=2, marker='o', markersize=5)\n",
                "    axes[0].plot(history.history['val_accuracy'], label='Validation Accuracy', \n",
                "                 linewidth=2, marker='s', markersize=5)\n",
                "    axes[0].set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
                "    axes[0].set_xlabel('Epoch', fontsize=12)\n",
                "    axes[0].set_ylabel('Accuracy', fontsize=12)\n",
                "    axes[0].legend(loc='lower right', fontsize=11)\n",
                "    axes[0].grid(True, alpha=0.3)\n",
                "    axes[0].set_ylim([0.5, 1.0])\n",
                "    \n",
                "    # Loss plot\n",
                "    axes[1].plot(history.history['loss'], label='Training Loss', \n",
                "                 linewidth=2, marker='o', markersize=5, color='#e74c3c')\n",
                "    axes[1].plot(history.history['val_loss'], label='Validation Loss', \n",
                "                 linewidth=2, marker='s', markersize=5, color='#3498db')\n",
                "    axes[1].set_title('Model Loss', fontsize=14, fontweight='bold')\n",
                "    axes[1].set_xlabel('Epoch', fontsize=12)\n",
                "    axes[1].set_ylabel('Loss', fontsize=12)\n",
                "    axes[1].legend(loc='upper right', fontsize=11)\n",
                "    axes[1].grid(True, alpha=0.3)\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.savefig('training_curves.png', dpi=150, bbox_inches='tight')\n",
                "    plt.show()\n",
                "    print(\"Training curves saved to 'training_curves.png'\")\n",
                "\n",
                "# Plot training history\n",
                "plot_training_history(history)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 8. Model Evaluation\n",
                "\n",
                "Evaluate the trained model on the test set and generate comprehensive performance metrics."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluate on test set\n",
                "print(\"Evaluating model on test set...\")\n",
                "print(\"=\" * 70)\n",
                "\n",
                "test_loss, test_accuracy = model.evaluate(test_generator, verbose=1)\n",
                "\n",
                "print(f\"\\nTest Results:\")\n",
                "print(f\"  Loss: {test_loss:.4f}\")\n",
                "print(f\"  Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate predictions for detailed analysis\n",
                "print(\"Generating predictions on test set...\")\n",
                "\n",
                "# Reset generator to ensure correct ordering\n",
                "test_generator.reset()\n",
                "\n",
                "# Get predictions\n",
                "predictions = model.predict(test_generator, verbose=1)\n",
                "predicted_classes = (predictions > 0.5).astype(int).flatten()\n",
                "true_classes = test_generator.classes\n",
                "\n",
                "print(f\"\\nTotal test samples: {len(true_classes)}\")\n",
                "print(f\"Predictions shape: {predictions.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate detailed metrics\n",
                "accuracy = accuracy_score(true_classes, predicted_classes)\n",
                "precision = precision_score(true_classes, predicted_classes)\n",
                "recall = recall_score(true_classes, predicted_classes)\n",
                "f1 = f1_score(true_classes, predicted_classes)\n",
                "\n",
                "print(\"Detailed Classification Metrics:\")\n",
                "print(\"=\" * 50)\n",
                "print(f\"Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
                "print(f\"Precision: {precision:.4f} ({precision*100:.2f}%)\")\n",
                "print(f\"Recall:    {recall:.4f} ({recall*100:.2f}%)\")\n",
                "print(f\"F1-Score:  {f1:.4f} ({f1*100:.2f}%)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Print full classification report\n",
                "print(\"\\nClassification Report:\")\n",
                "print(\"=\" * 60)\n",
                "print(classification_report(true_classes, predicted_classes, \n",
                "                           target_names=['NORMAL', 'PNEUMONIA']))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot confusion matrix\n",
                "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
                "    \"\"\"\n",
                "    Plot a detailed confusion matrix with annotations.\n",
                "    \n",
                "    Args:\n",
                "        y_true: True labels\n",
                "        y_pred: Predicted labels\n",
                "        class_names: List of class names\n",
                "    \"\"\"\n",
                "    cm = confusion_matrix(y_true, y_pred)\n",
                "    \n",
                "    fig, ax = plt.subplots(figsize=(10, 8))\n",
                "    \n",
                "    # Create heatmap\n",
                "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
                "                xticklabels=class_names, yticklabels=class_names,\n",
                "                annot_kws={'size': 20}, ax=ax)\n",
                "    \n",
                "    ax.set_title('Confusion Matrix', fontsize=16, fontweight='bold')\n",
                "    ax.set_xlabel('Predicted Label', fontsize=14)\n",
                "    ax.set_ylabel('True Label', fontsize=14)\n",
                "    \n",
                "    # Add percentage annotations\n",
                "    total = cm.sum()\n",
                "    for i in range(2):\n",
                "        for j in range(2):\n",
                "            percentage = cm[i, j] / total * 100\n",
                "            ax.text(j + 0.5, i + 0.7, f'({percentage:.1f}%)', \n",
                "                   ha='center', va='center', fontsize=12, color='gray')\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.savefig('confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
                "    plt.show()\n",
                "    print(\"Confusion matrix saved to 'confusion_matrix.png'\")\n",
                "    \n",
                "    # Print confusion matrix interpretation\n",
                "    tn, fp, fn, tp = cm.ravel()\n",
                "    print(f\"\\nConfusion Matrix Breakdown:\")\n",
                "    print(f\"  True Negatives (NORMAL correctly identified): {tn}\")\n",
                "    print(f\"  False Positives (NORMAL incorrectly labeled PNEUMONIA): {fp}\")\n",
                "    print(f\"  False Negatives (PNEUMONIA incorrectly labeled NORMAL): {fn}\")\n",
                "    print(f\"  True Positives (PNEUMONIA correctly identified): {tp}\")\n",
                "\n",
                "# Plot confusion matrix\n",
                "plot_confusion_matrix(true_classes, predicted_classes, CLASSES)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot ROC curve\n",
                "def plot_roc_curve(y_true, y_pred_proba):\n",
                "    \"\"\"\n",
                "    Plot the ROC curve and calculate AUC.\n",
                "    \n",
                "    Args:\n",
                "        y_true: True labels\n",
                "        y_pred_proba: Predicted probabilities\n",
                "    \"\"\"\n",
                "    fpr, tpr, thresholds = roc_curve(y_true, y_pred_proba)\n",
                "    roc_auc = auc(fpr, tpr)\n",
                "    \n",
                "    fig, ax = plt.subplots(figsize=(10, 8))\n",
                "    \n",
                "    ax.plot(fpr, tpr, color='#3498db', lw=3, \n",
                "            label=f'ROC Curve (AUC = {roc_auc:.4f})')\n",
                "    ax.plot([0, 1], [0, 1], color='#95a5a6', lw=2, linestyle='--', \n",
                "            label='Random Classifier')\n",
                "    \n",
                "    ax.fill_between(fpr, tpr, alpha=0.3, color='#3498db')\n",
                "    \n",
                "    ax.set_xlim([0.0, 1.0])\n",
                "    ax.set_ylim([0.0, 1.05])\n",
                "    ax.set_xlabel('False Positive Rate', fontsize=14)\n",
                "    ax.set_ylabel('True Positive Rate', fontsize=14)\n",
                "    ax.set_title('Receiver Operating Characteristic (ROC) Curve', \n",
                "                 fontsize=16, fontweight='bold')\n",
                "    ax.legend(loc='lower right', fontsize=12)\n",
                "    ax.grid(True, alpha=0.3)\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.savefig('roc_curve.png', dpi=150, bbox_inches='tight')\n",
                "    plt.show()\n",
                "    \n",
                "    print(f\"\\nArea Under ROC Curve (AUC): {roc_auc:.4f}\")\n",
                "    print(\"ROC curve saved to 'roc_curve.png'\")\n",
                "    \n",
                "    return roc_auc\n",
                "\n",
                "# Plot ROC curve\n",
                "auc_score = plot_roc_curve(true_classes, predictions.flatten())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 9. Sample Predictions Visualization\n",
                "\n",
                "Visualize sample predictions to qualitatively assess model performance on individual images."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def visualize_predictions(generator, model, n_samples=8):\n",
                "    \"\"\"\n",
                "    Visualize model predictions on sample images.\n",
                "    \n",
                "    Args:\n",
                "        generator: Test data generator\n",
                "        model: Trained model\n",
                "        n_samples: Number of samples to visualize\n",
                "    \"\"\"\n",
                "    # Get a batch of test images\n",
                "    generator.reset()\n",
                "    batch_x, batch_y = next(generator)\n",
                "    \n",
                "    # Get predictions\n",
                "    batch_predictions = model.predict(batch_x, verbose=0)\n",
                "    \n",
                "    # Plot\n",
                "    n_cols = 4\n",
                "    n_rows = (n_samples + n_cols - 1) // n_cols\n",
                "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 4*n_rows))\n",
                "    fig.suptitle('Sample Predictions', fontsize=16, fontweight='bold')\n",
                "    \n",
                "    for i, ax in enumerate(axes.flat):\n",
                "        if i >= min(n_samples, len(batch_x)):\n",
                "            ax.axis('off')\n",
                "            continue\n",
                "            \n",
                "        ax.imshow(batch_x[i])\n",
                "        \n",
                "        true_label = 'PNEUMONIA' if batch_y[i] == 1 else 'NORMAL'\n",
                "        pred_prob = batch_predictions[i][0]\n",
                "        pred_label = 'PNEUMONIA' if pred_prob >= 0.5 else 'NORMAL'\n",
                "        \n",
                "        correct = true_label == pred_label\n",
                "        color = 'green' if correct else 'red'\n",
                "        \n",
                "        title = f\"True: {true_label}\\nPred: {pred_label} ({pred_prob:.2%})\"\n",
                "        ax.set_title(title, fontsize=10, color=color, fontweight='bold')\n",
                "        ax.axis('off')\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.savefig('sample_predictions.png', dpi=150, bbox_inches='tight')\n",
                "    plt.show()\n",
                "    print(\"Sample predictions saved to 'sample_predictions.png'\")\n",
                "\n",
                "# Visualize predictions\n",
                "visualize_predictions(test_generator, model, n_samples=8)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 10. Model Summary and Conclusions\n",
                "\n",
                "Summarize the model performance and key findings from this implementation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Final summary\n",
                "print(\"=\" * 70)\n",
                "print(\"MODEL PERFORMANCE SUMMARY\")\n",
                "print(\"=\" * 70)\n",
                "print(f\"\\nDataset: Chest X-Ray Images (Pneumonia)\")\n",
                "print(f\"Total Training Samples: {train_generator.samples}\")\n",
                "print(f\"Total Validation Samples: {validation_generator.samples}\")\n",
                "print(f\"Total Test Samples: {test_generator.samples}\")\n",
                "print(f\"\\nModel Architecture: Custom CNN (3 Conv blocks + 2 Dense layers)\")\n",
                "print(f\"Total Parameters: {model.count_params():,}\")\n",
                "print(f\"\\nTraining Configuration:\")\n",
                "print(f\"  - Image Size: {IMAGE_SIZE}\")\n",
                "print(f\"  - Batch Size: {BATCH_SIZE}\")\n",
                "print(f\"  - Learning Rate: {LEARNING_RATE}\")\n",
                "print(f\"  - Epochs Trained: {len(history.history['accuracy'])}\")\n",
                "print(f\"\\nTest Set Performance:\")\n",
                "print(f\"  - Accuracy: {accuracy*100:.2f}%\")\n",
                "print(f\"  - Precision: {precision*100:.2f}%\")\n",
                "print(f\"  - Recall: {recall*100:.2f}%\")\n",
                "print(f\"  - F1-Score: {f1*100:.2f}%\")\n",
                "print(f\"  - AUC: {auc_score:.4f}\")\n",
                "print(\"\\n\" + \"=\" * 70)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save final model\n",
                "model.save('pneumonia_detection_model.keras')\n",
                "print(\"Model saved to 'pneumonia_detection_model.keras'\")\n",
                "\n",
                "# Save training history\n",
                "history_df = pd.DataFrame(history.history)\n",
                "history_df.to_csv('training_history.csv', index=False)\n",
                "print(\"Training history saved to 'training_history.csv'\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Key Observations\n",
                "\n",
                "1. **Model Performance**: The CNN model achieves reasonable accuracy on the pneumonia detection task, demonstrating the feasibility of using deep learning for medical image classification.\n",
                "\n",
                "2. **Class Imbalance**: The dataset contains significantly more PNEUMONIA samples than NORMAL, which was addressed using class weights during training.\n",
                "\n",
                "3. **Data Augmentation**: Augmentation techniques helped improve model generalization by artificially expanding the training set diversity.\n",
                "\n",
                "4. **Clinical Implications**: High recall for PNEUMONIA cases is particularly important in medical applications to minimize false negatives (missed diagnoses).\n",
                "\n",
                "5. **Limitations**: The model is trained on pediatric chest X-rays only and may not generalize well to adult populations without additional training."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}